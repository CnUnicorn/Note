## 多线程接口调用，共用一个Map做请求报文，导致Map内容被多个线程覆写

**场景：**

1、主线程从数据库分页查询客户基本信息

2、主线程将客户基本信息的list传入线程池，进行调用

**问题：**

1、请求报文通过Map的形式构建，然后转成JSON String

2、Map在主线程创建，子线程中对客户的基本信息（名称、证件号）进行覆盖

3、多个子线程会覆写同一个Map中的数据，导致子线程在调用时，请求报文可能已经被其它线程修改了



## Oracle表空间清理



## Oracle修改用户名密码

1、登录服务器，切换到oracle用户 `su - oracle`

2、以dba身份打开sqlplus。`sqlplus / as sysdba`

3、修改用户密码。`alter user 用户名 identified by 新密码`（新密码如果区分大小写，需要用双引号包上密码，如"TestCode"）



**如果密码重试多次，导致账号被锁定：**

1、通过以下命令解锁：`alter user 用户名 account unlock`

2、通过以下命令查询账号登录失败次数：`SELECT RESOURCE_NAME, LIMIT FROM DBA_PROFILES WHERE RESOURCE_NAME = 'FAILED_LOGIN_ATTEMPTS';`



## Oracle建表

Oracle建表要指定表空间，如果不指定，默认建在当前用户的默认表空间下。

如：modifyuser建表时如果不指定表空间，会建在modifyuser的表空间下，而不是其它表空间



## 异常未捕获导致线程中断

当try catch中指定捕获的异常范围无法覆盖代码中可能出现的异常时，会出现线程中断，并不会有错误提示。

如：

* hutool调用接口时，接口路径错误与访问的IP地址错误，抛出的是两种不同的异常，如果有一者未捕获到，会导致线程中断，且无提示，比较迷惑
* 当mapper执行插入操作时，某个字段超过数据库的长度，抛出的异常并不是IOException，如果捕获IOException，会捕获不到异常，导致线程中断；最后是在ERROR日志中发现Oracle报错信息，反推出为未捕获到异常

## 异常捕获

1、在Java中，当一个未捕获的异常导致程序终止时，通常会打印异常的堆栈信息。这是因为Java运行时系统会默认处理未捕获异常，并将异常信息输出到标准错误流（`System.err`）。

当程序抛出未捕获异常时，Java虚拟机会打印异常的堆栈跟踪信息，其中包含异常的类型、触发异常的位置（类名、方法名、行号等）以及异常调用链的信息。这对于调试和定位问题非常有用。



2、SLF4J本身并不能直接捕获`System.err`（Java标准错误流）的输出，因为SLF4J是一个日志门面（facade）接口，它主要关注于提供一致的日志API，而不是直接与Java标准错误流交互。SLF4J通过具体的日志实现（例如Logback、Log4j、Java Util Logging等）来处理日志的输出。

如果你想将`System.err`的输出记录到SLF4J支持的日志实现中，你可以考虑使用`System.setErr` 方法来更改`System.err`的输出流，将其重定向到一个自定义的`PrintStream`，然后在该`PrintStream`中通过SLF4J记录日志。

以下是一个简单的示例，演示如何将`System.err`的输出记录到SLF4J：

```java
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.PrintStream;

public class SystemErrLoggingExample {

    private static final Logger logger = LoggerFactory.getLogger(SystemErrLoggingExample.class);

    public static void main(String[] args) {
        // 保存原始的System.err输出流
        PrintStream originalSystemErr = System.err;

        try {
            // 将System.err重定向到自定义的PrintStream
            PrintStream customSystemErr = new PrintStream(System.err) {
                @Override
                public void println(String x) {
                    // 使用SLF4J记录日志
                    logger.error(x);
                }
            };
            System.setErr(customSystemErr);

            // 在System.err上执行一些操作
            System.err.println("This will be logged using SLF4J");

        } finally {
            // 恢复原始的System.err输出流
            System.setErr(originalSystemErr);
        }
    }
}

```



**遇到的坑，如果代码中出现了未捕获的异常导致程序中断，slf4j不会自动打印这个未捕获的异常（System.err。IDEA会输出System.err，打印这些未捕获的异常），这个时候就会让人非常的迷惑。**



**将`System.err`集成到中SpringBoot框架：**

Spring Boot框架本身并没有直接提供捕获`System.err`信息的功能。`System.err`通常用于标准错误输出，而Spring Boot主要关注于应用程序日志的处理，它使用日志框架（通常是SLF4J与Logback、Log4j2等实现）来记录应用程序日志。

如果你想将`System.err`的输出集成到Spring Boot应用程序的日志系统中，你可以通过自定义`PrintStream`并在其中调用日志框架的API来实现。以下是一个简单的示例，演示了如何将`System.err`的输出记录到Spring Boot的日志中：

```java
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.boot.CommandLineRunner;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

import java.io.PrintStream;

@SpringBootApplication
public class SystemErrToLoggerApplication implements CommandLineRunner {

    private static final Logger logger = LoggerFactory.getLogger(SystemErrToLoggerApplication.class);

    public static void main(String[] args) {
        SpringApplication.run(SystemErrToLoggerApplication.class, args);
    }

    @Override
    public void run(String... args) throws Exception {
        // 将System.err重定向到自定义的PrintStream
        PrintStream customSystemErr = new PrintStream(System.err) {
            @Override
            public void println(String x) {
                // 使用SLF4J记录日志
                logger.error(x);
            }
        };
        System.setErr(customSystemErr);

        // 在System.err上执行一些操作
        System.err.println("This will be logged using SLF4J");
    }
}
```



## ES相关

### _cat相关命令

```bash
_cat/indices?v          #查看集群中所有index的详细信息
_cat/indices/{index}?v  #查看集群中指定index的详细信息
_cat/segments?v         #查看各index的segment详细信息,包括segment名, 所属shard, 内存(磁盘)占用大小, 是否刷盘
_cat/segments/{index}?v #查看指定index的segment详细信息
_cat/allocation         #查看单节点的shard分配整体情况
_cat/shards             #查看各shard的详细情况
_cat/shards/{index}     #查看指定分片的详细情况
_cat/master             #查看master节点信息
_cat/nodes              #查看所有节点信息
_cat/count              #查看当前集群的doc数量
_cat/count/{index}      #查看指定索引的doc数量
_cat/recovery           #查看集群内每个shard的recovery过程.调整replica。
_cat/recovery/{index}   #查看指定索引shard的recovery过程
_cat/health             #查看集群当前状态：红、黄、绿
_cat/pending_tasks   #查看当前集群的pending task
_cat/aliases         #查看集群中所有alias信息,路由配置等
_cat/aliases/{alias} #查看指定索引的alias信息
_cat/thread_pool     #查看集群各节点内部不同类型的threadpool的统计信息,
_cat/plugins         #查看集群各个节点上的plugin信息
_cat/fielddata       #查看当前集群各个节点的fielddata内存使用情况
_cat/fielddata/{fields}     #查看指定field的内存使用情况,里面传field属性对应的值
_cat/nodeattrs              #查看单节点的自定义属性
_cat/repositories           #输出集群中注册快照存储库
_cat/templates              #输出当前正在存在的模板信息
```



### ES自动合并机制介绍

Elasticsearch 会自动执行文档合并（Merge）操作，以维护索引的健康状态、减少磁盘空间占用和提高查询性能。这个自动合并操作的策略主要涉及到 Lucene 引擎的内部工作机制。以下是 Elasticsearch 自动执行文档合并的一些关键策略：

1. **段合并：** Elasticsearch 使用 Lucene 引擎，该引擎将索引分割成多个小段（segments）。这些段包含一定数量的文档，并且随着时间的推移，文档的删除和更新会导致这些段中产生空洞。定期执行段合并可以清理这些空洞，减少磁盘空间的占用。
2. **后台合并：** 合并操作通常在后台异步执行，以避免对查询性能造成太大的影响。Elasticsearch 会自动监控索引的状态，并在需要时触发后台的合并操作。这包括删除了大量文档、文档更新频繁等情况。
3. **触发条件：** 自动合并的触发条件可以通过配置项进行调整。例如，你可以通过设置 `index.merge.policy.expunge_deletes_allowed` 和 `index.merge.scheduler.max_thread_count` 等参数来调整合并的触发条件和并发性。
4. **合并策略：** Elasticsearch 使用 Lucene 提供的合并策略，通常是基于段的大小和删除文档的数量。默认情况下，合并操作会尽量将小的段合并成较大的段，以减少段的数量。合并时也会处理已删除的文档，以清理空洞。
5. **合并延迟：** 合并操作可能会有一定的延迟，因为 Elasticsearch 会尽量将多个小的合并操作合并成一个更大的操作，以降低合并的开销。这样可以减少对系统性能的影响。
6. **手动干预：** 尽管 Elasticsearch 提供了自动的合并机制，但在某些情况下，手动触发 `_forcemerge` API 也是一种方式，特别是在需要立即释放磁盘空间时。然而，手动操作应该谨慎使用，因为它可能会影响系统性能。

总体而言，Elasticsearch 的自动合并机制是为了平衡查询性能和磁盘空间的利用效率。在绝大多数情况下，不需要手动介入，而是依赖 Elasticsearch 的自动管理机制。



### 释放ES磁盘空间

​	使用_delete_by_quey命令删除指定数据后，ES会将文档标记成deleted状态（逻辑删除）。如果需要释放磁盘空间，需要等ES自动处理合并segment操作；或者通过手动执行 forcemerge 操作来触发合并操作。

​	但是forcemerge操作**会消耗大量的系统资源和时间**，如果需要在生产环境执行，最好选择系统**低峰期**执行。因为合并的方式是，先将数据写入新的segment（分段），再删除旧的分段，索引在合并的过程中会额外占用磁盘空间，最多占用一倍。所以执行合并操作时，需要留够足够的磁盘空间。

```
POST 索引名称/_forcemerge
# 手动触发forcemerge，释放磁盘空间
POST 索引名称/_forcemerge?only_expunge_deletes=true
```

**forcemerge参数说明：**

* **max_num_segments**：要合并到的分段数。 要完全合并索引，请将其设置为1。 默认为简单地检查合并是否需要执行，如果需要，则执行它。默认值-1。
* **only_expunge_deletes**：该参数用于指定是否仅合并已删除的文档，而不合并仍然有效的文档，默认为**false**。 在 Lucene 中，文档不会从段中删除，只是标记为已删除，因此合并已删除的文档可以释放磁盘空间。 请注意，这不会覆盖index.merge.policy.expunge_deletes_allowed 阈值。
  1. 如果主要需求是释放磁盘空间，那么将该参数设置为true。表明合并操作专注于清理已删除的文档所占用的空间，而不触及仍然有效的文档。
  2. 如果该参数为false。表示合并所有文档，包含已删除的和仍然有效的。这种操作对整体性能更有帮助，但不会释放已删除文档所占据的空间。
* **flush**：强制合并后是否应该执行刷新。 Defaults to true.



### ES分片状态问题

ES磁盘空间不足时，写入操作并未报异常日志，但是ES中查询不到指定条件的数据。

发现ES部分索引状态变为RED和YELLOW，这些索引存在状态为UNASSIGNED状态的分片。



清除磁盘数据后，使用以下命令重新分配集群中的分片，将分配失败的分片重试一次分配：

`post _cluster/reroute?retry_failed=true`



**主分片与备份分片需要分布在不同的节点**上；如果 主分片+对应备份（replicas）的数量 > 节点的数量，会导致存在备份无法分配空间的情况（使用上面的命令分配分片时，会看到报错信息：No space left on device）。





## Mybatis

### #{}中指定jdbctype

在insert操作中，如果这个字段可能存在null，那么需要指定插入jdbcType（Mybatis不会自动转换），不然会报错

