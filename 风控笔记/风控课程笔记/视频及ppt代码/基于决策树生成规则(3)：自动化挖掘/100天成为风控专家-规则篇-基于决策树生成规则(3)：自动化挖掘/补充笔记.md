主要参考scikit-learn官方样例中，对Decision Tree结构的一篇样例。

这篇样例说明了决策树的数据结构，与存储数据的一些属性。

https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#

![image-20250210214055819](%E8%A1%A5%E5%85%85%E7%AC%94%E8%AE%B0.assets/image-20250210214055819.png)



## Tree structure

The decision classifier has an attribute called which allows access to low level attributes such as , the total number of nodes, and , the maximal depth of the tree. The method computes the depth of each node in the tree. also stores the entire binary tree structure, represented as a number of parallel arrays. The i-th element of each array holds information about the node . Node 0 is the tree’s root. Some of the arrays only apply to either leaves or split nodes. In this case the values of the nodes of the other type is arbitrary. For example, the arrays and only apply to split nodes. The values for leaf nodes in these arrays are therefore arbitrary.`tree_``node_count``max_depth``tree_.compute_node_depths()``tree_``i``feature``threshold`

Among these arrays, we have:

- `children_left[i]`: id of the left child of node or -1 if leaf node`i`
- `children_right[i]`: id of the right child of node or -1 if leaf node`i`
- `feature[i]`: feature used for splitting node `i`。feature列表存放的数字表示训练集中列的索引。如feature[i]=2，表示用于切分node `i` 的特征为X_train.columns[feature[i]]
- `threshold[i]`: threshold value at node `i`
- `n_node_samples[i]`: the number of training samples reaching node `i`
- `impurity[i]`: the impurity at node `i`
- `weighted_n_node_samples[i]`: the weighted number of training samples reaching node `i`
- `value[i, j, k]`: the summary of the training samples that reached node i for output j and class k (for regression tree, class is set to 1). See below for more information about .`value`