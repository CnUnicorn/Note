# 贷款年化利率

利率和坏账损失统一变换口径，比如都是年化的



贷款年化利率：

APR（名义利率）：

![image-20241022203848549](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022203848549.png)

IRR（真实利率）：

**IRR原始公式：**

**每一期的还款金额都折算到放款日同一时间点进行计算：**针对12期的产品，最后一期支付的还款金额，被占用了12个月；倒数第二期支付的还款金额，被占用了11个月；···依次类推，第一期支付的还款金额，被占用了1个月。

粗浅的理解：相当于被占用的金额，按照利息贬值，越晚还款的前贬值越多，最后折现成本金。

![image-20241022205242433](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022205242433.png)

公式介绍：

**n：年内还款频率。**

**T：还款年数。**

**如一年期限的产品，按月还款：n=12，T=1**

**五年期产品，按月还款：n=12，T=5**

![image-20241022205926211](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022205926211.png)



![image-20241022215639310](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022215639310.png)

**从不同角度考虑IRR：**

![image-20241022215719399](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022215719399.png)





**从本金占用的角度考虑的IRR公式：**

（每期归还的利息 / 每期平均占用的本金）*一年周转次数

![image-20241022212443137](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022212443137.png)

![image-20241022215813435](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022215813435.png)





**从满额占用本金时间的角度考虑的IRR公式：**

业内也叫**生息月份**或者**生息期数**，也是**久期**的概念，只不过叫法不同：

![image-20241022212941753](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022212941753.png)

![image-20241022215838341](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022215838341.png)



**APR和IRR的区别：**

从公式的角度看，APR与IRR的两种公式的形式都是一样的

APR与从占用平均本金的IRR公式对比：差别在，分母变成了平均占用本金

APR与从占用满额本金时间的IRR公式对比：差别在，贷款期限（月）变成了，占用满额本金的月份。



对于相同的还款利息，相同的还款本金：计算得到的APR一定是比IRR要小的。

从本金角度考虑：APR（名义利率）认为每一期都占用了满额的本金；而IRR考虑到随着还款进行，占用本金变少，所以相同利息下，IRR要大于APR。

比如三期的网贷：本金5000，每期还款1767.65。APR是24%，IRR是36%。

![image-20241022213742373](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20241022213742373.png)



# 1.策略开发和调优

规则和模型本质上都是策略的工具，只不过模型是复杂的规则（或者说规则是简单的模型）。

规则和模型都是为了业务策略服务的，规则和模型只是业务策略中得一个环节，只对自己得风险识别能力负责，至于要使用什么数据、阈值设定、调用顺序、使用位置等都是策略需要考虑得事情（特征变量由专门岗位的人产出，策略直接进入分析阶段）。

![image-20250105141824316](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105141824316.png)

## 1.1规则认识和类型

### 1.1.1策略维度

策略维度如下：评分类综合分中，目前消费分还没涉及到。

![image-20250105140839872](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105140839872.png)



### 1.1.2规则强弱程度

![image-20250105141003480](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105141003480.png)

弱规则一般是连续性数值变量，且变量**具有一定的排序性**。



### 1.1.3规则案例

![image-20250105141218246](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105141218246.png)

重点在：数据含义，规则描述，规则强度（案例中红色是强规则）

## 1.2.规则分析全流程介绍

### 1.2.1.规则全流程

规则完整流程：

1. 规则离线开发和评估
2. 规则上线和监控

![image-20250105144148183](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105144148183.png)



### 1.2.2.规则离线开发和评估

![image-20250105144336656](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105144336656.png)

1. 人工制定规则
   * 现有风险识别再制定规则目标，基于专家经验
2. 量化制定规则
   * 先做出衍生变量，再基于数据分析进行规则筛选

**实际业务中两者结合使用。**



**量化规则开发流程：**

通常情况下变量开发会提前用，用以快速分析上线，需要提前规划。 ![image-20250105144608612](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105144608612.png)



### 1.2.3.规则上线验证和监控

![image-20250105144857828](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105144857828.png)

1. **规则上线：**制定好的规则发布到决策引擎
2. **规则验证：**验证上线规则的配置、**AB测试分流比例是否正确**；==**上线后规则命中率与线下测算时命中率的误差**==
3. **规则监控：**对规则命中率的稳定性按周期（日/月/周）持续监控，如出现异常需及时排查。
4. **规则调整：**对已上线规则进行贷后分析，根据表现调整规则阈值。



## 1.3.基于单变量生成规则

单变量制定一般步骤：

![image-20250105145848936](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105145848936.png)



### 1.3.1 变量初筛

![image-20250105145935142](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105145935142.png)

变量初筛主要是对变量进行描述性统计分析（**如平均值、最大值、最小值、标准差等**）以及缺失率、众数占比等指标计算，**对不符合要求的变量先进行一轮剔除，这样可以减少后面二轮筛选规则的压力**。



==变量初筛过程中，还要注意一下特殊值，规则可能需要单独考虑特殊值：==

可以先看接口文档，了解大致的特殊值。

再通过代码看实际的分布，比如通过toad.detector来看：可以看到唯一值，标准差，各分位点的值等（众数占比需要自己算）

* 空值占比（null，空字符串等），以及空值的含义
* -999或者999，以及这些特殊值的含义
* 最小最大值等



众数占比高可能会导致无法分箱，没有排序性（连续性变量）。

### 1.3.2 变量分箱

![image-20250105151937779](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105151937779.png)

 主要关注分箱的注意事项：

1. 必须包括变量所有值，不能丢失信息
2. 分箱数量不宜太多，一般再5-8之间
3. 每箱数量占比至少在5%以上，数量太少没有统计意义
4. 如果有缺失值，需要单独分一箱（缺失值可能也有单独的含义）



**分箱算法分类：**

![image-20250105152305072](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105152305072.png)

 

### 1.3.3 分箱统计量

**分箱后统计量（好坏客户占比与坏账率）：**

![image-20250105153843493](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105153843493.png)

主要是**边际占比**与**区间占比**：

* **边际占比**：**分箱下的XX数量** / **XX总数量**（纵向对比）
* **区间占比**：**分箱下的XX数量** / **分箱内总客户数**。一般只关注坏客户，也叫区间坏账率



### 1.3.4 分箱统计量含义

**分箱后统计量的含义：**

![image-20250105154435504](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105154435504.png)

一般来说，规则和模型都要求变量有明显的单调性，这样符合业务的可解释性。



### 1.3.5 WOE-公式和含义

![image-20250105154753073](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105154753073.png)

WOE公式：

$$WOE_i = ln(\frac{该分箱内边际坏客户占比}{该分箱内边际好客户占比}) = ln(该分箱内边际坏客户占比)-ln(该分箱内边际好客户占比)=ln(\frac{Bad_i}{Bad_T}/\frac{Good_i}{Good_T})=ln(\frac{Bad_i}{Bad_T})-ln(\frac{Good_i}{Good_T})$$



### 1.3.6 IV-公式和含义

![image-20250105155503924](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105155503924.png)

分箱内好坏客户边际占比越大，IV越高，说明变量好坏区分度越明显。

### 1.3.7 IV-使用标准

![image-20250105160451166](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105160451166.png)

规则和模型变量筛选时是一样的：除IV外，也要考虑变量间的相关性。相关性高的变量==**综合考虑IV、变量的坏账排序性（业务可解释性）、规则效果LIFT**==等，选择性保留变量。



### 1.3.8 IV-代码实现

![image-20250105161041598](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105161041598.png)

如果三方包不满足使用要求，也可以自己写一个IV计算函数，但**前提是分箱、WOE也要自己提前处理好**。



### 1.3.9 制定规则阈值

#### 1.3.9.1 规则效果-两个期望

1. 拒绝客户占总体客户的比例（命中率）不宜过高

   * 命中率高影响业务规模
   * 每个环节维度不同，对风险识别互为补充。每个环节做最有把我的事情。
   * 由以上两点，规则阈值一般会比较极端，要的实现效果就是**通过大部分客户，而只拒绝一少部分客户，单规则一般拒绝比例不超过5%**

2. 拒绝客户中，坏客户占比越高越好，同时好客户占比越低越好

   尽可能抓坏，并减少误杀

#### 1.3.9.2 规则效果-5各评估项

前三个是可量化的指标，后两个是业务解释性相关。

![image-20250105163116028](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105163116028.png)

1. 精准率

   由于实际情况中，坏样本浓度比较低，很难达到较高的精准率（bad_rate），一般通过LIFT来比较（bad_rate / 整体坏样本率；或者）

2. 召回率

   精准率和召回率是需要同时兼顾的：**希望在精准率达到要求的情况下，尽可能提升召回率**。如果某条规则精准率达到80%，但是只拒绝了0.1%的坏客户这条规则是需要再考虑的（特殊情况，比如极端的反欺诈规则需要视实际情况而定）。

   精准率和召回率两个指标是互斥的。这个与通过率和坏账率平衡类似。 

#### 1.3.9.3 规则阈值制定方法-IV分析法

分箱后，直接拒绝某一个分箱的客群。这个和分箱方法有很大的关系。**这种方法实际上是按照分箱来拒绝**。

![image-20250105164225433](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105164225433.png)

#### 1.3.9.4 规则阈值制定方法-极端值检测

![image-20250105164855081](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250105164855081.png)

极端值检测通过“**枚举分位数**”的方式，**枚举可能的极端值，作为备选的阈值**。

分位数，也称分位点：是概率的概念。即在一个集合内，小于这个值的所有样本的概率。比如，1%分位点，小于这个值的样本的个数为整体数量的1%。

正经定义：分位数指的就是连续分布函数中的一个点，这个点对应概率p。若概率0<p<1，随机变量X或它的概率分布的分位数Za，是指满足条件p(X≤Za)=α的实数 [1]。

**通常使用的分位点如下：**(toad.detector也有分位点，但是只包含1%和99%，没有那么细)

[0.005, 0.01, 0.02, 0.05, 0.95, 0.98, 0.99, 0.995]：小于0.5%、1%、2%、5%；大于95%、98%、99%、99.5%

[0.5%, 1%, 2%, 5%, 95%, 98%, 99%, 99.5%]



## 1.4.基于交叉表生成规则

### 1.4.1 交叉表介绍

 

1. 交叉表本质是变量的笛卡尔积。![image-20250108211618678](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108211618678.png)



2. 交叉表的复杂度介于单规则和评分卡模型之间。同时兼顾维度和复杂度两点。![image-20250108211813434](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108211813434.png)



3. 交叉表的前置条件

   * **基于IV筛选除预测效果好的变量池，从中选择交叉所需的变量组**。一般原则是：交叉变量最好是不同维度的，且相关性不高，这样综合效果最优
   * **对变量进行分箱操作，连续型变量需要有排序性。**有排序性才有直观的可解释性。离散型变量很多时，也可以分箱。
   * **总样本和坏样本数量足够多**。总样本数不变，两个变量交叉后，样本会被稀释到各个格子内。如果总样本和坏客户数数量不够的话，会导致样本充分性不足，无统计意义。

   ![image-20250108211955245](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108211955245.png)

   ![image-20250108212356902](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108212356902.png)



### 1.4.2 交叉表规则生成和评估

交叉表制定步骤：

1. 基于透视表统计坏客户数和总客户数
2. 基于坏客户数和总客户数统计量，计算出区间坏账率（badrate）和客户数占比
3. 基于格子的区间坏账率和客户占比制定规则

![image-20250108212714841](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108212714841.png)



**步骤一：**透视表

第一个透视表是坏客户数统计，第二个透视表是总客户数统计。使用pandas.crosstab+dataframe.pivot_table方法制作交叉表并统计数量；可以用seaborn热力图直观展示badrate

![image-20250108212950683](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108212950683.png)



**步骤二：**计算区间坏账率（badrate）和区间客户占比。

![image-20250108213130627](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108213130627.png)



**步骤三：**基于格子的区间坏账率和客户占比制定规则。（平衡通过率和逾期率） 。

评估精准率、召回率、通过率 

![image-20250108213244674](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108213244674.png)



应用场景：D类调优（收紧风险，但不太影响通过率）

![image-20250108213903570](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250108213903570.png)



### 1.4.3 如何寻找变量

分为离散型变量与连续型变量两类进行探索(**本质上还是根据IV和排序性挑选**，此外还要考虑变量间的相关性)

可以通过pandas自动判断类型来区分连续型和离散型变量，object一般来说都是离散型变量。可以用`DataFrame.select_dtypes(include=None, exclude=None)`挑选离散型变量。

toad对离散型变量也能分箱（默认，

1. 离散型变量
   * 剔除掉离散值过多的变量。做交叉表类别太多。
   * 观察各离散值的badrate，挑选出排序性较好的离散变量。
2. 连续型变量
   * 分箱后根据IV和排序性挑选。



## 1.5.基于决策树生成规则

### 1.5.1 什么是决策树

![image-20250120203056388](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120203056388.png)

### 1.5.2 决策树的生成过程

决策树一般生成过程，相当于通过特征变量对样本的特征空间做**非线性划分**，所以也说决策树是“**非线性**”模型。

![image-20250120203210868](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120203210868.png)

### 1.5.3 决策树算法

![image-20250120203513701](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120203513701.png)



### 1.5.4 CART决策树

![image-20250120203559848](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120203559848.png)

二分类中：p=1/2时（无法区分），基尼系数最大，此时效果最差。

### 1.5.5 CART分类树-基尼系数

![image-20250120204149378](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120204149378.png)  

  

![image-20250120205007624](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120205007624.png)

基尼指数：反映从数据集D中随机抽取两个样本，其类别标记不一致的概率。因此，Gini(D)越小，则数据集D的纯度越高。



### 1.5.6 CART分类树-变量二分法

连续型变量：

![image-20250120205212382](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120205212382.png)  



离散型变量：

![image-20250120205518066](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120205518066.png)



### 1.5.7 CART分类树-递归生成

![image-20250120205857518](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120205857518.png)

### 1.5.8 CART回归树-预测方式

![image-20250120210741848](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120210741848.png)

![image-20250120212201151](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120212201151.png)

与回归的度量标准也不同，类似损失函数。

回归树也有分类的思想（聚类）。相同类之间的目标变量值才会更接近，方差才会更小 。

* 分类树：使用基尼系数切分。
* 回归树：使用残差平方和（RSS）切分。

### 1.5.9 CART回归与分类树的预测方式

* 分类树：叶子节点中概率最大的类别作为当前节点的预测类别。
* 回归树：叶子节点中样本的y均值作为回归的预测值。



==CART决策树还有剪枝的过程，课程中不涉及需要另外看资料==

### 1.5.10 决策树规则生成与调参

**调参：（决策树及调参代码见[1.5.11](#s1)）**

1. **改变决策树算法本身的参数**。比如叶子节点样本数量（比例），树深度等等。比如**控制树深度，可以大致控制叶子节点是单规则（1层），二维交叉规则（2层）还是多维组合规则（多层）**。树深度不完全决定组合规则的数量，只决定上限（可能会提前分裂结束）。
2. **改变入模变量的组合**（python-combinations方法）。不同的入模变量组合（**不同子集的基尼系数不同**），决策树会有不同的分裂过程，得到不同的规则组合方式。



![image-20250120212705572](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120212705572.png)

**注意事项：**

* 过拟合：规则复杂可能在训练样本上效果好，OOT上效果差。
* 树深度：树深度过深可能会导致规则过于复杂，不利于上线后监控维护。==**一般规则包含的变量不超过三个**==
* ==**调参**==：

![image-20250120212857741](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120212857741.png)



### 1.5.11决策树Python代码

主要依靠sklearn的API。

sklearn只实现了ID3和C4.5，只实现了CART算法，并且是调优过的。（**暂不支持类别型特征**）

![image-20250120213121965](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120213121965.png)

![image-20250120213344758](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120213344758.png)

![image-20250120213450214](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250120213450214.png)

<a name="s1"></a>

通过调整入模变量组合，以及获得组合路径的代码，在这三节课中：

1. **基于单变量生成规则（2）：Python代码实操**。决策树可视化，以及展示参数调整。

2. **基于决策树生成规则(3)：自动化挖掘**。决策树分裂路径记录（组合规则）（深度优先遍历递归）

3. **并行规则集性能测试(2)：Python实操**。针对不同的入模变量组合，循环训练得到组合规则结果。这部分没有直接的代码，实际上是复用第二节课里的核心代码（决策树路径记录）。

   1. 主要代码如下（得到变量组合）：

      ![image-20250218215110743](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250218215110743.png)

   2. 对不同入模变量组合进行决策树训练

      在单组入模变量训练的基础上，套了个循环，把所有入模变量的组合都跑一边，最后把结果存到一起。核心函数还是第二个课里的**extract_tree_rules（）**方法。

      1. 变量r是所有变量的个数。
      2. 单变量规则，树的深度定为1，组合子集个数为2。**入模变量两两组合，得到单变量规则**。
      3. 多变量组合规则，树的深度定为2及以上，组合个数为所有变量个数（**如果选择将组合数减少，那么会多出非常多的组合，得到很多的组合变量**）。

      ![image-20250218215419551](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250218215419551.png)



## 1.6.规则泛化效果评估

OOT和训练集一般是在开始的时候就一起设计好，然后特征变量一次性全部加工好，提高效率。

**选取OOT的时候，最好还要考虑一下OOT与训练集时间段内，有没有做过规则的调整（可能会导致客群有差别）**。



### 1.6.1 样本选择的几个注意点：

* OOT时间窗口在训练集之后。
* OOT**一般选3个月以上**的样本，并按月分别评估（为满足统计意义上的样本数量最小要求）
* OOT需要和训练集一样，具有一定的贷后表现时间（**OOT在没有完全表现的情况下，建议最少也得有3个月的表现**）
* OOT的客群的风险水平与训练集相同（**部分原因：比如中间有过策略调整，有可能会出现OOT客群与训练集出现不同，可能会导致规则效果不稳定**）。简单衡量风险水平的方法：可以观察训练集和OOT的平均坏样本率和相同特征下的分箱分布情况。

![image-20250211210354463](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250211210354463.png)



![image-20250211210851777](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250211210851777.png)



### 1.6.2 评估指标

**逾期率评估指标：（训练集和OOT都可以看）**

* 命中率
* 精准率（precision，badrate）
* 召回率
* lift（一般来说希望lift在3以上）
* ==逾期率下降幅度（除绝对值外，还可以看相对值）==：（样本总的坏账率-规则通过后样本坏账率）/样本总坏账率



**指标浮动范围：**

1. 如果时间外样本上的指标在分析样本指标的一定范围内浮动，则说明泛化样本上效果打标，如果超出范围下降严重则说明不达标浮动范围一般不超过10%，严格的不超过5%。
2. 比如，分析样本lift为3，时间外样本lift为1，效果衰减较多（说明规则可能过拟合），需要重新调整规则；如果时间外样本lift为2.7-3.3之间，不超过10%的范围内波动，则说明规则的泛化能力达标。



**通过率评估：**

精准率，召回率，lift等指标需要有Y标签，导致通过率可能不太准确。**可以采用最新的样本来评估规则通过率影响，最新样本的命中率也可以和训练集和OOT上的命中率做对比，如果波动太大，需要考虑使用**。

![image-20250211211911379](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250211211911379.png)

## 1.7 规则集线下性能测试

规则集主要有三个指标：

1. 综合命中率

2. 整体坏账率（规则集命中的客户中的坏客户比例）（统计一个规则集整体命中的样本里的坏账率bad_rate，与样本平均坏账率一比可以得到规则集整体的lift。计算规则集整体的性能）

3. 相互覆盖率（规则与规则之间覆盖的程度，是**独立贡献**的指标。如果一个规则完全被其它规则覆盖，那么该规则在规则集中就没有存在价值了，统计**单一命中率**） 

   相互覆盖率要统计两个：（1）规则两两间的覆盖度；（2）去除多余规则后，统计每条规则单一命中率（如果是一条样本一行，先打上该条样本命中了几条规则的标签，再去按特征统计单一命中率。这个标签可以用于综合命中率统计，按照命中规则数量value_counts()，可以统计的更细致）。

   1. 一种简单的方法是，规则集中的所有规则，两两组合，观察命中结果的交叉情况，同时命中规则一与规则二的样本（交集部分），分别占仅命中规则一和规则二的样本比例（交集占两条规则各自的比例都要统计）。如果两个规则命中的样本完全一致，或者某一条规则命中的样本完全被另一条规则所覆盖，那么这条规则需要弃用。

      <img src="%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250224213157358.png" alt="image-20250224213157358" style="zoom:40%;" />

      实际案例如下：

      1. 绿色规则表名两条规则命中的样本一摸一样，保留一条即可。

      2. 规则0是规则1和规则5的组合规则，规则0是被规则1和规则5所覆盖的。

      <img src="%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250224213530024.png" alt="image-20250224213530024" style="zoom:80%;" />

![image-20250218203830100](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250218203830100.png)



![image-20250218204412075](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250218204412075.png)



如果要剔除规则1，那么规则1剔除后需要重新计算规则2和3的单一命中率（**先剔除无效规则，再统一计算单一命中率**）

![image-20250218204653685](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250218204653685.png)



规则命中打标代码：

```python
import pandas as pd

# 示例 DataFrame
data = {
    'A': [1, 2, 3, 4],
    'B': [4, 3, 2, 1],
    'C': [3, 2, 4, 1],
    'D': [1, 2, 3, 4]
}
df = pd.DataFrame(data)

# 定义标签函数
def add_flags(df, conditions):
    """
    为 DataFrame 添加标签
    :param df: 输入的 DataFrame
    :param conditions: 条件字典，格式为 {'flag_name': condition}
    :return: 添加了标签的 DataFrame
    """
    for flag_name, condition in conditions.items():
        df[flag_name] = condition(df).astype(int)  # 将布尔值转换为 0 或 1
    return df

# 定义条件
conditions = {
    'flag1': lambda df: (df['A'] >= 2) & (df['C'] >= 3),
    'flag2': lambda df: (df['C'] <= 3) & (df['D'] >= 1)
}

# 应用条件并添加标签
df = add_flags(df, conditions)

print(df)
```



## 1.8 策略调优

### 1.8.1 策略调优介绍和方法论

#### 1.8.1.1 策略调优介绍与调优方向

1. 策略调优介绍：![image-20250226213151974](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250226213151974.png)

   一般来说，市场环境好的时候，策略比较激进，占用市场；市场环境不好的时候，主要靠存量客户，对新客做谨慎处理。![image-20250226213451063](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250226213451063.png)



2. 策略调优方向

   两个核心指标：通过率、逾期率。

   两个调优方向：

   完美情况：降低逾期率的同时，提高通过率。

   * **A类调优（Ascending）**：提高通过率。从当前拒绝客户中寻找好客户。尽可能在逾期率不变的情况下，提高通过率。
   * **D类调优（Descending）**：降低逾期率。从策略通过的客户中寻找差的客户进行拒绝。尽可能在通过率不变的情况下，降低逾期率

![image-20250226213804968](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250226213804968.png)



3. 策略调优步骤

   ![image-20250226214512067](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250226214512067.png)

#### 1.8.1.2 A类调优的业务场景

![image-20250226214731914](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250226214731914.png)

1. 资金充足有业绩压力

   资金充足时，现有通过率下的客户无法消耗完。一般发生在银行金融机构，有明确贷款规模的业务指标。（纯业务导向）

2. 策略过于保守

   在风险可控有很大盈利空间的情况下，可以适当提高通过率，让收益最大化。

   比如业务初期冷启动阶段，处于风险审慎考虑对于新客的通过率往往比较低，随着业务发展逐渐积累了一些贷后表现，如果发现风险非常低，说策略过于保守。

3. 监控报表通过率下降（日常遇到较多）

   通过监控报表发现，规则或模型命中率逐渐变高导致通过率下降。此时首先需要定位原因，然后进行相应调优，让通过率回到对应的水平。



**A调优方法论：**

![image-20250226215149011](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250226215149011.png)

A类调优没有贷后表现，实际预测时需要借助一些量化方法或者AB测试，难度相对高一些。

A类调优可以分为宏观和微观两个层面：

1. **宏观调优（调整幅度较大）**

   客群下探。当一个客群风险稳定可控后，想要继续放大业务量，除本现有客群精细化策略调优外，还可以尝试对拒绝客群进行下探。下探客群由于风险更高，审批策略更严，且额度一般更低，定价更高。

2. **微观调优（调整幅度较小）**

   * **拒绝回捞**：从策略流中前面节点命中拒绝的客户中有条件的捞回好客户
   * **策略放松**：现有策略放松，比如规则cutoff的放松调整。
   * **策略下线**：对现有效果较差的策略进行下线处理
   * **策略替换：**用新的策略替换，需进行“置入置出”swap-in，swap-out评估新旧策略的效果。尽可能保证逾期率不变的情况下，通过率上升。



#### 1.8.1.3 D类调优的业务场景

![image-20250226215845089](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250226215845089.png)

**D类调优业务场景**：

1. 监控发现逾期上升

   通过监控报表发现，逾期率有明显上升的趋势，需要及时定位原因，调整策略

2. 实际逾期率超过预期目标（与离线分析有偏差）

   **实际逾期率比离线分析时要高很多**，且超过了预期的目标值，需要调整成与目标一致

3. 放款头寸变少

   机构放款资金不足，优先给资质较好的客户

4. 市场环境下行控制风险敞口



![image-20250226220208453](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250226220208453.png)

D类调优也可以分为宏观和围观的两个层面

D类调优从通过客户中寻找相对较差的客户拒绝，因为客户有贷后表现，离线分析效果更准确，难度较A类调优相对小一些。

**D类调优**：

1. 宏观层面（调整幅度大）

   客群层面的收紧。许多机构是**以模型分层（融合模型的等级，比如A-F）为主导的策略体系**。当某分层的风险过高甚至击穿安全垫的时候，出于风险控制考虑可能会停止高风险客群的业务。比如原先有ABC三层客群，直接把C客群拒绝，或者C客群有条件通过（调整较大）

2. 围观调优

   * **策略收紧**：比如将策略cutoff收紧，通过率也会同时下降。
   * **策略替换**：用新策略替换旧策略，尽可能保持通过率不变的情况下，逾期率下降。也需要swap-in，swap-out
   * **策略新增**：在现有策略维持不变的情况下，新增加策略，以达到预期的目的，但通过率也会同时下降。

### 1.8.2 单变量规则的A类调优(1)：拒绝客户坏账预测 

#### 1.8.1 规则阈值放松

![image-20250310220316135](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250310220316135.png)



#### 1.8.2.2 规则阈值放松的难点

A类调优的一个难点是：**被拒绝的客户无放款，没有贷后表现（风险未知），因此对于“是否可以放松”以及“放松程度”是难以量化分析的**。（贷前被拒绝的客户的好坏是难以判定的（坏客户的概率大，也有可能是好客户））。

![image-20250310220334769](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250310220334769.png)



#### 1.8.3 拒绝样本贷后表现的量化方法

![image-20250310220738463](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250310220738463.png)

常见的有3个方法可以参考：

1. **回归预测（通过规则本身的趋势预测）**：如果规则的通过样本分箱badrate有一定的单调性，可尝试基于通过样本的badrate拟合回归模型来预测拒绝样本分箱下的badrate。**该方法的使用条件是规则本身具备一定的区分能力，即规则本身badrate有单调趋势（规则本身排序性好）**
2. **其它强变量（根据其它独立变量预测）**：不依赖于规则通过样本badrate的单调排序性，而是借助其它的强变量来预测拒绝样本贷后表现，即规则通过样本的badrate没有明显的单调性，但不影响其它强变量的区分效果。在实际业务中，**一般这种强变量大多是模型分，或者融合模型分**
3. **实际测试**：如历史做过“灰度测试”或“AB测试”，可参考历史数据预估；如没有历史测试，可通过“随机测试”放行想要放松的客户，通过时间贷后表现来准确获取信息。

PS：对拒绝样本贷后表现进行预测本身是一个非常难的问题。如果有多种量化分析的方法，最好是多种方法结合起来使用（**即以上几种方法是可以同时使用的**），**综合多个维度分析**得到的结果，说服力就更强，预测值就更准确。



##### 1.8.3.1 回归预测方法（ 规则本身有较好的排序性）

大前提：**规则变量分箱后在通过样本上就有较好的排序性。**

![image-20250310221654066](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250310221654066.png)

通过多项式拟合（可以用python也可以用excel）

python：numpy.polyfit()——最小二乘法进行多项式拟合。

![image-20250310221729627](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250310221729627.png)

excel：趋势线拟合。

![image-20250310223220011](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250310223220011.png)



##### 1.8.3.2 其它强变量预测坏账率（一般是模型分）

​	当单变量的badrate单调性没那么强的时候，可以用其它强变量（风险排序能力比较强）预测拒绝样本的坏账率（一般是模型分）

![image-20250317212237602](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250317212237602.png)

通过模型分预测规则的坏账率，步骤（坐上图为规则1的分箱与badrate）：

1. 对**规则通过样本**进行模型分打分，分箱后计算每一箱的badrate（左下角小图）

2. 统计模型分对**规则拒绝样本的打分分布**。（==由于拒绝样本没有贷后表现，假设模型分在相同分箱下对通过和拒绝的样本的badrate一样==）。

   然后根据分箱下的数量和badrate求出拒绝样本的“坏客户数量”（右下角的小图）。通过模型分分箱，大致估计拒绝样本的badrate与坏样本数量。

   ==每箱坏客户数求和 / 该拒绝段总样本数 = 173/2000=8.65%==

   

##### 1.8.3.3 实际测试

![image-20250317213544209](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250317213544209.png)

1. 随机测试（**所有客户所有规则直接通过，通过这部分客户的贷后表现来预估**）

   * **分流比例**：比例不宜过高（一般控制在2%以内，另一本书上写0.5%~1%）。保证最小统计要求的情况下，避免随时过于严重（坏客户放太多导致坏账高）
   * **豁免**：所有客户直接通过。只打分不生效，直接通过审批，**且不会被决策流后面的策略拒绝**（如果是串行），否则贷后表现可能失真。
   * **优缺点**：信息准确，无需预测，有实际贷后表现，缺点是需要一定的观察周期，并且会产生一定的坏账损失（这部分的风险敞口需要提前计算好，判断对风险调优的价值）。

2. 如果历史有过“**AB测试**”或“**灰度测试**”，可以使用测试期间样本的贷后表现预估。

   AB测试和灰度测试的区别：AB测试是同时发生的，灰度测试的陪跑是先前的。

   * **AB测试**（**部分规则不生效直接通过，针对某条规则直接通过，比所有规则全部放行要少一些坏客户**）：如果某条规则上线时进行过AB测试。比如A组（对照组）的模型分全部只打分，不拒绝；B组（实验组）的打分并生效。从A组可以获取低于cutoff的客群的贷后表现（badrate），作为B组的近似估计。

   * **灰度测试（陪跑）**：如果规则策略上线前存在灰度测试，灰度期间只打分不生效，可以用来预估规则拒绝样本的badrate。灰度时间距今至少要有1个月以上的表现期（如果是观察首逾率指标，如果是观察dpd30+指标要更长的表现期），且灰度期间积累的样本量要满足统计数量的最小要求。

     （1）通过另一个特征在通过样本上的表现情况来预估拒绝样本的贷后表现。（比如中征分陪跑，得到各分分箱的badrate，然后根据拒绝样本的中征分估计badrate）。

     （2）同规则历史陪跑，可以根据通过样本获得各个分箱的badrate。用来预估拒绝样本的badrate。



### 1.8.3 单变量规则的A类调优(2)：效果测算

参考“**基于单变量规则的A类调优效果测算案例**”这个excel，通过预测拒绝分箱的badrae，拉出细分到每一箱变量的badrate、累计通过数量、累计通过率、通过率比例的提升幅度（放开这一箱后的通过率 - 之前的通过率）/之前的通过率、累计坏客户数量、坏账率（坏客户数 / 通过样本数）、坏客户比例的提升幅度。

1. 首先选取时间尽可能靠近现在的样本，选取一个提取分析样本的时间窗口

   包含两个部分：

   * 规则通过的样本，且有贷后表现
   * 规则拒绝的样本，无贷后表现（有变量的分布情况）

2. 通过单变量的badrate拟合后，预测拒绝分箱的badrate

   <img src="%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250331205730453.png" alt="image-20250331205730453" style="zoom:150%;" />

3. 调优后效果测算

   计算规则放松后分箱的坏客户数量，来统计通过率与坏账率。（红色为预测的坏账率，及各项指标）

   ![image-20250331205846890](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250331205846890.png)

   如何放松：

   * **通过率上涨幅度**：因为通过率和坏账率不是一个量纲，不能直接通过绝对值比较，可以根据**通过率和坏账率上涨的幅度**来做对比。
   * **单箱lift**：放松阈值的同时，还可以看单箱lift，一般来说放松后的单箱lift还是比较小，并结合通过率和坏账率上涨幅度，那么整体还是可以放松的。

   例子：比如上图中，第五箱放松后通过率提升幅度15.56%，坏账率上升10.71%，且单箱lift为1.79（可以简单的用badrate / 通过样本的坏账率，这样算出来lift偏高，因为放松后，整体badrate是升高的）；继续放松到第6箱时，通过率提升幅度与坏账率提升幅度比较接近了，且单箱lift变高了，不考虑继续放松。

   * **自己的想法**：可以估算一下放松后的这部分样本，带来的收益能否覆盖放松的样本带来损失的本金。

4. 放开后的处理

   可以先上线后做AB测试，观察贷后表现，随后再决定是否正式



### 1.8.4 并行规则集的A类调优（1）：理论介绍

#### 1.8.4.1 A类调优介绍与步骤

规则和模型的调优方法一样，本质都是策略的调优。

A类调优步骤：

1. 筛选单一命中率和单一命中纯度高的规则，放松后整体通过率提升较多。
2. 预估放松规则后，逾期率上升的程度，综合评估通过率与逾期率选择是否放松。
3. 放松后重新计算整体通过率（可能会有重复命中的情况），观察是否达到预期。如果没有，重复前两步（或者提前挑选好所有方案，全部计算后选择最好的方案）。

![image-20250407204303599](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407204303599.png)



#### 1.8.4.2 通过单一命中率筛选可调整规则

1. 并行的规则集，好处在于能获得所有数据，对于策略调优较为友好。

![image-20250407204709226](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407204709226.png)

2. 单一命中率、单一命中纯度概念

* 自然命中率：规则A的命中率
* 单一命中率：只有规则A命中，其它并行规则均未命中的数量占比
* **单一命中纯度**：**单一命中率/自然命中率**，反应单一命中的占比，其它占比未与剩余规则交叉命中的部分。

![image-20250407204929243](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407204929243.png)

3. 如何通过单一命中率筛选可调整的规则

   * 寻找连续型的弱规则，排除**强规则、政策性规则、以及非连续型规则（可调整空间不大）**
   * 对“**单一命中率、单一命中纯度**”**两者比例均较大**的进行优先筛选。**单一命中率降低多少会直接反应在整体的综合命中率上**。（大部分情况单一命中下降，整体命中会增加差不多的数值，单一命中纯度越高，放松后被其它命中的概率越低，那么整体命中率增加的越多。最极端的情况，整条规则下掉，整体通过率增加单一命中率的数值大小）。**单一命中率为该条规则调整后通过率增加的上限，单一命中纯度为规则调整后通过率增加的可能性**

   举例：RULE0与RULE7的单一命中率与单一命中纯度均较高，放松后整体命中率可能有较多的提升。

   ![image-20250407205859039](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407205859039.png)

   将RULE7单一命中率和纯度都较高，放松后，整体通过率提升值正好与规则命中率下降值相同。

   ![image-20250407210407214](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407210407214.png)

#### 1.8.4.3 通过逾期率筛选可调整规则

​	在放松阈值的同时，还需要评估规则放松后逾期率上升的程度，这个时候就需要预估**拒绝样本的坏账率**，综合评估通过率和坏账率情况判断是否放松这条规则。

​	个人想法：**如果放松了多条规则，可以简单的把所有规则放松后的坏样本直接加起来做统计**。因为尽可能挑选的都是单一命中纯度较高的规则，那么**不同规则放松后的样本存在重复的可能性也较低**，且直接累加也可以做逾期的保守估计。

![image-20250407210621082](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407210621082.png)



拒绝客户逾期率有两种情况可以判断：

1. 有历史拒绝数据

   曾经做过随机测试，随机分流一部分客户，所有规则直接通过，有完整贷后表现；规则上线前做过AB测试或者灰度测试，对于规则执行但决策不生效的样本（分流仅针对部分规则通过），筛选规则拒绝段的贷后表现。优先释放历史逾期率较低的规则。

2. 无历史拒绝数据

   * 做随机测试获取拒绝段贷后表现，但**需要一定的观察周期**，且要付出一定的逾期损失，一般比例较小，同时也需要内部评估是否需要做这个事情。
   * 基于**区间坏账率单调性**的性能判断，如果单调性较强说明规则区分效果较好，拒绝段逾期率大概率会按照单调趋势延续，可大致预估或者通过建回归模型量化方法预测逾期率，该种情况下拒绝样本的逾期率一般较高。因此，**优先选择单调性较差的规则释放拒绝段，往后延续的拒绝样本坏账率会稍微低一些**。

   一般来说，通过逾期率预测的方法，准确度要低于随机测试。

![image-20250407211020395](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407211020395.png)

举例：RULE0、RULE4的badrate单调性较好，预估拒绝样本的badrate较高；RULE7的badrate单调性较差，预估拒绝样本的badrate较低。

![image-20250407213023645](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407213023645.png)



#### 1.8.4.4 计算规则集性能再调整

​	当调整完规则后，重新计算整个规则的通过率的变化情况，因为不同规则会有重复命中的情况。

​	如果通过率没有达到预期，可以重新返回前两步调整，也可以提前列出所有备选方案，计算选择最好的组合。

![image-20250407213339465](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250407213339465.png)

### 1.8.5 决策流程上的A类调优：拒绝回捞

#### 1.8.5.1 拒绝回捞的概念

* 广义：广义上理解可以等同于A类调优，涵盖各类调优方法，即从被拒绝的客户中找出可准入的客户。

* 狭义：狭义上理解，是决策流程中的一个回捞动作，或者回捞节点，如下图。

![image-20250416205804958](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416205804958.png)

​	在决策流程中，不同节点中使用的数据有限，会有一点的误杀，从被拒绝的客户中，重新筛选客户。如上图，在被欺诈规则和信用规则拒绝的情况下，如果通过回捞规则，可以准入。



从另一个角度理解拒绝回捞（拒绝规则可以理解为挑出坏人，回捞规则可以理解为挑出好人）：

	1. 从规则的角度看，通过的客户中，好客户占大多数；拒绝的客户，我们认为坏客户占大多数。
	2. 在拒绝的客户中，再切一刀，筛选出一部分客户，这部分客户中绝大多数都是好客户，极小部分的客户是坏客户。

![image-20250416210346759](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416210346759.png)

#### 1.8.5.2 拒绝回捞策略的核心逻辑

​	拒绝回捞策略的核心逻辑：选取**明显的好客户特征**，并且**这些特征最好与前面已执行审批策略的数据维度相关性越小越好**，通过这些特征或者特征组合，从拒绝客户中进行捞回。

* 明显的好客户特征：

  **可以参考白名单的筛选规则**，比如，客户是公务员、事业单位或者500强集团企业员工；再比如客户公积金缴存基数大于xxx，等等。这些都属于明显的好客户特征，通过贷后表现分析也是如此，这类客户的风险很低。

* 为什么用明显的好客户特征：

  拒绝客户是因为命中某些规则而被拒绝的，说明了在某个维度上的风险是很高的。**如果想让其它维度风险高的客户通过，必须有非常强的特征维度来覆盖掉这个风险，或者抵消这个风险，才能被回捞通过**。

![image-20250416210718643](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416210718643.png)

#### 1.8.5.3 拒绝回捞策略规则设计

​	拒绝回捞策略设计上一般以**规则及规则的组合为主**（模型分也数据规则的范畴），根据规则区分效果的强弱、以及对通过率的影响综合考虑。

1. 如果想要**回捞的力度大**，提高更多的通过率，可以选择用**比较强的单一规则**进行回捞

​	比如前面被某些规则拒绝的客户，如果现在**命中了机构的内部白名单，则回捞通过**；反之则保持拒绝状态。这里的逻辑是我们更相信内部白名单的效用，更有说服力。

2. 如果想要回捞的更加精准，可以选择使用**多维度交叉的规则组合**

​	比如前面被某些规则拒绝的客户，如果现在命中了机构的白名单，并且基于三方数据源的融合模型分>700，则回捞通过；反之则保持拒绝状态。这种规则组合的形式对通过率提升不如商议中，但回捞更精准。

![image-20250416211856162](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416211856162.png)



​	**回捞的规则及规则组合不仅限于一种，可以从多个维度设置多条规则形成规则集**。可以是**串行或者并行**。下面是一个**并行回捞**规则集的示例（并行的好处是，可以看到每个规则的情况，方便未来调优）：

	1. **无差别回捞**：优质客户白名单、优质客户+推测收入较高，则直接回捞。这里需要注意一点，这里的白名单或者优质客户在决策流前面的节点中有没有使用过，如果前面使用过这些规则了，这里需要另外考虑。
	2. **有针对性的回捞**（三个案例）：
	 * 针对负债类规则的回捞：近2年有负债无逾期+违约成本高。（一般贷前会有负债类的规则，负债高的客户大概率会被拒掉，这里重新回捞。大部分情况下，负债高是由风险的，比如说负债高收入高、负债高但从未逾期）。
	 * 资金紧张评级低+模型分A>600：从多头和信用风险的角度去评估回捞。（对资金不是非常饥渴，且模型分比较高）
	 * **征信白户** + 模型分B>700：有些机构是不做征信白户客户的。但其它做下沉客户，比如消金等机构，会从征信白户中，结合一个非常强的**三方数据模型分**补充征信信息，再回捞一部分可能的好客户。（如果这个三方数据模型分排序性较好，可以尝试把高分客户回捞，阈值可以设置的相对严格一点）

![image-20250416212541861](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416212541861.png)



实际执行案例：

 	根据以往贷后表现，发现模型分大于等于800的客群，只有1.31%的badrate，可以尝试对征信白户切出>=800分进行回捞。

![image-20250416214739807](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416214739807.png)



#### 1.8.5.4 拒绝回捞策略流程设计

1. 确定不可回捞的对象，哪些拒绝客户是不可回捞的（**底线**）

   比如，政策准入、黑名单等硬性底线规则不允许回捞。

2. 确定需要回捞的对象，要对哪些拒绝客户进行回捞

   这个需要结合业务考虑，比如只对信用规则拒绝的客户回捞，也可以只对欺诈规则拒绝的客户回捞，或者同时回捞，不同的回捞对象对应的回捞节点位置不同。

![image-20250416215148878](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416215148878.png)



#### 1.8.5.5 拒绝回捞策略离线分析

1. **确定回捞变量**：通过数据分析和业务经验，**挖掘明显的好客户特征变量**，或者加工出有针对性的捞回变量，统称“用于回捞的变量”

2. **回溯回捞变量**：与历史样本数据对齐（包括通过、拒绝样本在策略上的决策数据，以及通过样本的Y标签）。回捞变量可能已经在历史样本中了，则不需要回溯。同时统计历史样本数据的逾期率，即大盘风险，作为后续回捞策略的参照。

3. **筛选回捞变量**：筛选各回捞变量下的客群，**分别统计其被审批策略规则拒绝的比例**，主要用于评估是否有回捞的空间。如果比例非常小说明回捞空间不大可以忽略，如果比例适中则可以考虑进行回捞。比如白名单中的大部分客户都会被审批规则拒绝，那么回捞的空间就比较小了。

4. **设计回捞策略**：根据步骤3分析结果初步设计回捞策略，代码执行回捞策略，并测算回捞效果，评估通过率、逾期率指标。

   4.1. 通过率比较好计算，主要看整体回捞策略的命中率，并且细致一点还会看回捞策略中每个规则的单一命中率情况。

   4.2. 逾期率的计算要分情况，如果是用已有贷后表现的变量做回捞，比如已有策略在用的模型分，那就不需要预估了，可以直接拿来用。如果用没有贷后表现的变量做回捞，那就面临着拒绝样本没有贷后表现的问题（如果变量不在策略中，可能还需要先回溯），如果有历史的测试结果，比如随机测试或者AB测试等，可作为参考来预估逾期率的水平。**一般情况下回捞客群逾期率和整体相比，要有明显低的又是，比如整体坏账bad rate是2%，那么回捞客群的bad rate最好控制在1.5%以下，否则捞回的和整体没有什么区别，也就失去做的意义了**。

5. **评估回捞效果**：最后根据评估指标，来调整回捞策略，重复步骤4。评估完后还要用近期样本再计算回捞策略的命中率，以评估策略的稳定性，因为历史样本和近期客群可能有一定的变化。

![image-20250416220052540](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416220052540.png)



#### 1.8.5.6 拒绝回捞策略上限和监控

1. 执行AB测试

   确定回捞策略以后，出于对风险审慎的原则，可以通过AB测试的方式上限，比如切出来20%的流量执行回捞策略，并打上标签，方便后续分析资产质量（实验组）。剩余80%的比例保持原有策略，不执行回捞（对照组）

2. 线上监控

   回捞客户可能有一定的风险，上线后要重点关注捞回资产的质量。

   * **上线初期**：资产还没有贷后表现。主要关注捞回人群占比的稳定性，是否与离线分析时保持一致。并且如果出现某一天捞回量突然上升的情况，也需要立即排查原因。**毕竟捞回量越高，风险就一般会越高，这是一个预警信号**。
   * **上线中期**：当资产开始具备短期贷后表现后，如首逾率FPD7/15/30+，那么就可以比较捞回的资产与大盘的风险差异。如果捞回资产风险与大盘接近或者要高，考虑下架处理。如果捞回资产风险较低，有明显优势，那么可以逐步放大流量比例，稳定后切到全量。
   * **上线后期**：随着贷后表现丰富，可进一步分析DPD30+term3/4/5等风险暴露更充分的指标衡量风险。稳定后可全面上线。另外持续监控回捞命中率的情况，对于单一命中率为0或者失效的规则进行再迭代优化。

![image-20250416222931388](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250416222931388.png)



### 1.8.6 客群对象上的A类调优：客群下探

#### 1.8.6.1 客群下探概念

​	**客群下探**相比具体策略规则的微调，客群的调整属于更宏观层面，**策略规则调整好比‘战术调整“，而客群调整好比”战略调整“。**客群下探的过程中，除了风控策略本身，还需要业务、产品、开发等一起联动配合，涉及到的部门更多，考虑因素更多。

​	主要应用场景：在业务冷启动的过程中，出于审慎考虑，通过率普遍较低。随着业务发展积累了一定的贷后表现后，如果客群风险可控且安全垫较高，说明此时风控策略偏保守。在公司业务做的偏保守的时候，都有空间做客群下探。

![image-20250421212134540](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421212134540.png)



客群下探意义：

* **市场端角度**：尽量留住自己的资产，避免资源浪费，留住护城河。自己不留住，其它同业竞品也会去做。

* **资产端角度**：丰富公司资产结构，多业务并行发展。做出更多差异化的产品，避免内卷。

* **风控端角度**：可以大幅提升授信审批通过率，但同时大盘风险也会提升，所以一般下探客群的策略设计上更严苛，且产品上也会控制风险。

以上均从**收益最大化角度**来说。理论上只要有有盈利空间，且满足监管要求，就可以一直下探，直到边际效应递减，再考虑收紧。

![image-20250421212654626](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421212654626.png)



#### 1.8.6.2 客群下探实现方式

​	大多数企业的贷前策略体系属于**“模型为主，策略为辅”**的，即通过模型输出的风险等级对风险分层，并以此为基础实现额度和定价的差异化指定，所以客群下探的一种有效方式就是**“下探模型分层的风险等级”**。

​	模型为主的体系，对模型的精准度要求较高。为了保证模型效果持续的好，需要不停的优化。

​	这种下探的好处是，下探一个等级后，通过率会上升的比较快，同时逾期率也会有所升高，需要关注贷后的逾期情况。

![image-20250421213236797](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421213236797.png)

#### 1.8.6.3 客群下探节奏

​	阶梯式下探，在模型分层分后，再单独增设一些审批规则，实现有条件地通过（相当于从高风险客群中筛选更优质地客户通过）。这种下探就比较丝滑，没有一步到位，类似阶梯式的逐步下探。

​	**核心思想和业务初期通过白名单做业务冷启动是一个道理，待有了一定贷后表现以后再根据实际情况决定是否下探，整体下探节奏是阶梯式逐步开展的，便于控制整体风险。**

​	以上只是下探的一种方式，具体还需要结合业务需求进行调整。

​	此外，除了风控策略放松外，**还包含了产品要素上的设计，比如说下探初期对额度和还款期限进行控制，等有了具体表现之后，比如逾期、支用率，再根据情况进行调整**。

​	比如上线后发现支用率比较低，那么可能会调整额度盖帽（提额）或差异化定价（高价客群降价）。

![image-20250421214145320](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421214145320.png)



#### 1.8.6.4 客群下探效果测算

​	通过率、逾期率测算。

*  一般来说，使用近期样本测算的通过率普遍比较准确且简单

* 逾期率测算的难度比较大，如果有随机测试和ab测试，可进行参考；如果没有，建议参考公司已有的类似产品，或者去市场调研**同类额度定价产品的逾期表现**，再已有结合通过客户的贷后表现按风险等级区间坏账的排序性做线性测试，综合来预估逾期率。（这是一个没有把握的事儿，信息越全，角度越广，结果越准确）

![image-20250421215019143](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421215019143.png)



​	业务测算：业务规模、收益。

​	预估下探后，每个月新增的放款规模大概有多少。月均申请客户数量可通过历史预估，用信转化率可根据经验或者参考公司同类产品、行业同类产品，件均额度（授信额度）需要乘上一个额度系数，客户不一定会全部提款。

$每月新增放款规则=C等级月均申请客户数量\times用信转化率\times件均额度\times额度系数$



![image-20250421215631420](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421215631420.png)



#### 1.8.6.5 客群下探风险预警和处置

​	客群下探属于战略上的调整，除了策略调整和基本测算外，还需要做好风险监测和预警

​	上线后，如果实际风险比预期风险要高，如何做应对的措施。从风险管理角度来看，一般需要提前制定2各风险线，一个是预警线，一个是拉闸线：

* **拉闸线**：风险底线，坚决不能逾越，超过了就直接停业务。

* **预警线**：在即将达到拉闸线之前打一个提前量，提前预警，预警触发后查找原因进行调整，避免业务恶化后停掉。

  **预警时机也需要结合业务情况具体来制定，可以评估业务风险的滞后程度**。比如先息后本，预警线可以多靠前一点；等额本息的，预警线可以稍微宽松一些。

![image-20250421220316789](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421220316789.png)

#### 1.8.6.6 客群下探的产品设计

**从产品要素设计角度控制风险的几点原则**：

1. 风险越高，额度越低。从资金方的角度来看，推送的客户额度越高，风险普遍也较低。
2. 风险越高，定价越高。利润空间主要集中在下沉客户，虽然优质客群风险低，但是规模和定价都不会太高。
3. 风险越高，还款期限越低。
4. 风险越高，资金占用越低。一般来说低风险客户，可以选择先息后本，也可以选择等额本息；高风险客户，一般选择等额本息。

![image-20250421220915322](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421220915322.png)

​	实际案例：

![image-20250421221547520](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421221547520.png)



​	客群下探过程中，产品角度上的其它考虑：从产品上控制是一把双刃剑。如果额度偏低，定价偏高，有可能导致授信通过率提高，但是用信转化率偏低，业务整体规模还是没打开。

​	**调整用信通过率最直接的方法是，调整额度和定价**，通过AB测试来做客户激活率上的优化。

​	一般经验而言，**风险低的优质客群更关心定价**，因为额度上给的都差不多，比的是定价的优惠政策；而**对于下沉客群而言，对于定价反而不敏感，更关心额度多少**，各家定价给的都差不多，此时额度的需求更多一些。

![image-20250421221719096](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250421221719096.png)

# 2.贷前策略

## 2.1定额策略

### 2.1.1定额策略概述与目标

* 授信额度：金融机构为借款人提供的最大贷款金额，是客户获得的一种权益额度。
* 借款额度：是指借款人在金融机构给予的最大贷款金额范围内，实际借贷的金额。

从产品角度看，一般消费分期类的信贷产品授信额度等同于借款额度，而对于**信用卡分期及循环贷现金贷产品**，是需要区分授信额度和借款额度的，两类产品在风控流程中也会体现出差异化。

1. 前者通常来说依附于某种业务场景，比如京东商城买某个产品，使用了分期，那么这一笔的授信就等同于借款额度。个人理解为通常意义下的单笔单批。
2. 信用卡类，现金贷类的，一般是循环额度，额度下可多次提款。

![image-20250427210347326](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250427210347326.png)



​	额度策略好坏会直接影响客户的**动支情况、预期情况、以及收益情况**。

1. **动支情况**：如果额度过低，没达到客户的预期，客户可能不会使用额度，则不产生收益。

2. **逾期情况**：如果额度过高，超过客户还款能力，客户如过度使用则可能导致逾期。

3. **收益情况**：动支比例低会影响业务规模，导致利息收入提升小；逾期风险高会导致坏账损失多，导致收益缩水。

   授信额度在影响动支和逾期上，是比较矛盾的两点，不宜过高也不宜过低，需要**达到一个平衡来达到收益最大化**。**额度策略的主要目的就是收益最大化**。

![image-20250427211326772](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250427211326772.png)



### 2.1.2定额策略-两种场景描述

**一、分期贷款场景（单笔单批）**

$损失率=\frac{坏账总金额}{放款总金额}=(\frac{坏账户数}{总账户数})\times(\frac{坏客户平均坏账金额}{所有客户平均放款金额})$

损失率可以按下图中公式分解成两个部分（上面的公式换了几个用词。个人理解，账户数实际是**客户数**，正好与策略模型开发的客户维度对应），如果左边：

1. 左边的**户数损失率**：可以通过贷前规则与贷前模型来控制（开发时以客户维度）。
2. 右边的**贷款额控制比**：从分子的角度看，如果认为坏客户是不还款的话，额度给的过高，那么坏账金额过高，**会拉高平均坏账金额**，损失率整体变大；从分母的角度看，如果额度给的偏低，那么具备还款能力的好客户的借款金额偏小，**会拉低平均放款金额**，导致分母变小，损失率整体变大。

**贷款额控制比**的公式分子分母，正好与**逾期率**、**动支情况**对应。

对于单笔单批业务来说：**额度策略的衡量指标**就是$\frac{坏客户平均坏账金额}{所有客户平均放款金额}$

![image-20250427212011388](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250427212011388.png)



**二、循环贷款场景**

此时放款金额 <= 授信金额

$损失率=\frac{坏账总金额}{放款总金额}=(\frac{坏客户数}{总客户数})\times\left \{ (\frac{坏客户平均限额}{所有客户平均限额})\times(\frac{坏客户额度使用率}{所有客户平均额度使用率}) \right \} $

下图公式可以拆解为三个部分（限额就是授信额度）：

1. **户数损失率**：授信模型策略控制。

2. **限额控制比**：坏客户平均授信额度越高，分子越大，损失越大；好客户平均授信额度越小，分母越小，损失越大。

3. **额度使用率**：一般情况下，坏客户的额度使用率高，分子较大，损失大；好客户的额度使用率较低，分母较小，损失大。

   这里的额度使用率有两种情况：一种是欺诈嫌疑，奔着薅羊毛借了不还的；另一种是偿还能力有限的客户，这种客户在其它金融机构可能也有借款，对资金的饥渴程度较高。

   从分子的角度看，额度越高，坏账使用率越高，导致损失越大；从分母的角度看，额度越低，好客户的支用意愿减少，分母越小，导致损失越大。（**尽可能拉起好客户的动支意愿，以及提高好客户的授信额度，降低坏客户的授信额度**）。

![image-20250427214844754](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250427214844754.png)

对于循环贷款场景来说：额度策略的衡量指标有两个，**限额控制比**和**额度使用率**。



**三、额度策略总结与个人理解**

1. 个人理解的额度策略：**尽可能拉起好客户的动支意愿，以及提高好客户的授信额度，降低坏客户的授信额度**。但实际又是下沉客户的利润空间较大，坏客户的额度也不能给太低，需要寻找一个**平衡点**。

2. 与1.8.6.6中客群下探的产品设计思路有异曲同工之处（**高风险低额度，高风险高定价；低风险高额度，低风险低定价**）。且一般来说，好人更关心定价（各家机构给的额度都差不多）；坏人更关心额度（各家给的定价差不多）。个人觉得也可以这么理解，**额度策略更偏向于为坏客户定制**。



**四、额度策略的难点**

1. 策略制定依赖专家经验

   量化方法较少，很多机构还是以来专家经验。

2. 数据维度

   **经济水平、资金需求**等方面缺少准确的数据维度来衡量。

3. 验证额度的准确性需要较长的时间

   线上验证需要较长时间的贷后表现进行观察判断。

4. 额度策略的评估方法缺少依据

   额度效果评估的方法较少。

![image-20250427223905047](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250427223905047.png)

### 2.1.3 定额策略-数据维度

​	项目冷启动初期，可能简单粗暴，所有客户一个维度。等业务运行一段时间后，有数据积累后，可以定制化定额。

​	定额主要依靠三个数据维度；

* 风险
* 收入
* 需求

![image-20250526192636653](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526192636653.png)



**一、风险维度**

​	损失公式： $EL=PD\times EAD\times LGD$

* 日常的风控模型就是PD模型。
* EAD（风险敞口）就是额度（或者说余额）
* LGD（违约损失率）：可能损失的金额占风险敞口的比例（违约不一定全部损失，比如有催回、或者资产可抵押、质押的）

随着风险的上升，应给予的额度应该要变低。

![image-20250526192758382](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526192758382.png)



**风险数据类型：**

* 模型分：A卡、征信模型分、三方数据源
* 强变量：征信查询多头、三方多头共债、历史逾期数据

![image-20250526193229754](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526193229754.png)

额度策略与审批策略的应用差异：

* 审批策略的模型分：要求尾部有区分度，用于抓坏
* 额度策略模型分：更关注“排序性”，不一定要求尾部区分度强，但整体要有明显过度的排序性，因为额度模型是面向所有通过客户，在每个风险分层下制定相应额度。



**二、收入负债维度（还款能力）**

**收入、负债数据能反映出借款人偿还债务的能力。**光看收入，可能收入高，负债也高，导致偿还能力弱，需要两者结合。

1. **收入数据**

   * **强相关：**社保、公积金、信用卡额度（他行额度）、房贷、固定资产、月消费金额、工资流水（一般是线下提供，比如房贷）、模型预测（依靠弱相关数据构建模型，形成强相关数据）、外部数据
   * **弱相关：**年龄、学历、职业、城市、是否有车、手机品牌、手机价格、地址稳定性。（通过客户画像分析弱相关数据和收入的关系）

   有强相关的数据时，也需要弱相关的数据，因为评估收入是比较困难的，需要从不同维度叠加起来评估。

2. **负债数据**

   * 征信数据（每个月未结清应还款金额，按不同类型区分）
   * 外部共债数据

   一般以征信为主，征信报告的数据相对来说比较准确。

![image-20250526193640707](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526193640707.png)



**三、需求维度**

需求与额度的关系：

​	**一般来说，没有借款需求的客户的授信额度要高于有需求客户的授信额度。**这一对比也可以反映在给客户授信后是否动支的表现上，或者是否用满额度上。一般来说，用满额度的客群风险是要高于未用满额度的客群。同时还需要考虑到，没有需求的客户可能是因为额度不够等原因未发起支用，因此提额，也可以起到“促动支”的作用，即促使授信到用信的转化率提升。

需求数据包含：

* 埋点数据：自家app的一些行为数据
* 营销响应模型分
* 动支模型分（比如，授信后是否在七天内发起动支等）
* 征信查询数据
* 外部借贷行为和意向等相关数据

![image-20250526194457652](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526194457652.png)



### 2.1.4 定额策略-收入测算

1. **通过社保推算收入**

   缴纳比例在不同地域，可能有不同的值。医疗、失业保险也可按照比例计算，作为交叉验证手段。

   按照以上公式推算的收入可能会出现一些失真的情况。

   * 一种是工资超过了当地最高缴纳基数
   * 另一种，部分公司按最低标准缴纳，或者不全额缴纳，则收入推算偏低。可以加一个判断逻辑，**先判断实际缴纳额是否超过了工作当地的最低标准缴纳额，如果超过了，则说明推算出的收入不是按照最低标准缴纳的，那大概率就是按照真实工资缴纳，此时推算结果更加准确。**

![image-20250526204241766](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526204241766.png)

![image-20250526204705648](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526204705648.png)



2. **通过公积金推算收入**

缴存基数、缴存比例，在不同城市都不一样，而且每年会变化。如果做跨区域的信贷业务，涉及多个城市省份的，需要梳理出不同城市最新的关于缴存基数、缴存比例的映射表，一次来准确判断。

![image-20250526205342900](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526205342900.png)



3. 通过房贷推算月收入

   ​	房贷推算收入的逻辑是：如果借款人一直按期还房贷（月供）且未出现逾期，则代表该借款人截至目前的收入水平是至少可以覆盖月供的。

   ​	一般来说，月收入的**20%以下**还月供会相对轻松；**20%~50%**之间属于一般水平；而**50%以上**甚至更高压力更大。大部分人会在月供和生活质量之间进行平衡，所以在借款人当前未逾期的情况下，可以按照**30%~40%**的平均水平作为房贷系数来进行推算。

![image-20250526205929136](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526205929136.png)

​	如果无法获取征信报告，但是有相关房产信息，比如说房产价格，也可以进行推算。通过房产价值乘上一个系数，来大致估计收入。

![image-20250526210409445](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526210409445.png)

4. 通过信用卡额度推算收入

   **信用卡额度 = 月可支配收入 / 最低还款比例（最低还款比例一般是10%），这样可以保证月可支配收入至少够还信用卡欠款的最低还款**。

   ​	通过假设可支配收入占工资的比例，根据信用卡额度来倒推收入。

![image-20250526210651798](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526210651798.png)



5. 有效月收入

   ​	前面推算的收入不一定有效，以公积金为例，借款人近几个月的公积金如果断缴，那么即便基于缴存基数和比例推算出的收入，是无法代表借款人真实状态的，因为断缴很可能说明客户还款能力已经出现了问题。因此，**在推测收入前增加一些限制条件，如果满足了条件再进行收入推算，这时的收入就叫“有效月收入”。**

![image-20250526211238134](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526211238134.png)



* **基于公积金的有效月收入**有下面几个，是且的关系，**有一个不满足就不进行推算**。

![image-20250526211635126](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526211635126.png)



* **基于房贷的有效月收入**：贷款状态得是正常的，不然月收入就是非有效的，这个是硬性条件。

  ​	贷款进度方面，块结清的借款人，风险肯定比刚开始还贷款的借款人低；通过总还款金额（本息总和）与本金的比例可以间接推算出贷款利率，而贷款利率可以**间接让我们知道客户的风险级别**，比如房贷利率不到4%，那一定是优质客户，而利率8%以上的客户信用风险肯定比上一个要高。**可以根据这些软条件设定差异化的有效月收入，比如在推算公式前加一个惩罚系数。**

![image-20250526211937292](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526211937292.png)



* **基于信用卡额度的有效月收入：**贷款状态、使用状态、使用长短（开卡时间太短，评估收入可能不准确）、异常剔除（过高，过低的额度剔除）均为硬性条件，否则推算的收入可能会失真。

  与房贷相同，可以通过额度使用率、多头情况等软条件设置相关的惩罚系数，最终确定有效月收入。

![image-20250526212859715](%E9%A3%8E%E6%8E%A7%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0.assets/image-20250526212859715.png)